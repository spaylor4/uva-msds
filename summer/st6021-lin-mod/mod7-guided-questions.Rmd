---
title: "Module 7 Guided Questions"
author: "Shannon Paylor"
date: "7/25/2020"
output: html_document
---

```{r setup, include=FALSE, }
knitr::opts_chunk$set(echo = TRUE)
nfl <- read_table2("nfl.txt")
```

## Question Set Overview

We will continue to use the “nfl.txt” data set from the tutorial for module 7.

#### Question 1

From the tutorial, the model with the “best” BIC has $x_2$, $x_7$, $x_8$ as predictors.  We will continue to work with this regression model for the rest of this question.

```{r regression}
nfl_lm <- lm(y ~ x2 + x7 + x8, data = nfl)
```

#### Question 2

The PRESS statistic can be used in model validation as well as a criteria for model selection.  Unfortunately, the `regsubsets()` function from the leaps package does not compute the PRESS statistic.  The PRESS statistic can be written as $PRESS = \sum{[y_i - \hat{y}_i]^2} = \sum(\frac{e_i}{1 - h_{ii}})^2$ where $h_{ii}$ denotes the $i$th diagonal element from the hat matrix. Write  a  function  that  computes  the  PRESS  statistic  for  a  regression  model. Hint: the diagonal elements from the hat matrix can be found using the `lm.influence()` function.

```{r press_func}
press_statistic <- function(lin_mod) {
  press <- sum((lin_mod$residuals/(1 - lm.influence(lin_mod)$hat))^2)
  return(press)
}
```

#### Question 3

Using the function you wrote in part 2, calculate the PRESS statistic for your regression model from part 1.  Calculate the $R^2_{Prediction}$ for this model,  and compare this value with its $R_2$.  What comments can you make about the likely predictive performance of this model?

```{r press_calc}
press_statistic(nfl_lm)
```

```{r rsquared_pred}
1 - press_statistic(nfl_lm)/sum(anova(nfl_lm)$`Sum Sq`)
```

```{r}
summary(nfl_lm)
```

The $R^2_{Prediction}$ for this model is 0.7325, compared to its $R^2$ of 0.7863. Because these values are both relatively large, the model is likely a reasonably good predictor.

#### Question 4

Delete half the observations (chosen at random), and refit the regression model. Calculate the $R^2_{Prediction}$ for this model. How well does this model predict the number of games won? Hint: the `sample()` function will be useful here.

```{r refit_sample}
nfl_sample <- nfl[sample(nrow(nfl), 14), ]
nfl_lm_sample <- lm(y ~ x2 + x7 + x8, data = nfl_sample)
summary(nfl_lm_sample)
```

```{r}
1 - press_statistic(nfl_lm_sample)/sum(anova(nfl_lm_sample)$`Sum Sq`)
```

For the model based on a sample of half the data, I got $R^2$ = 0.8572 and $R^2_{Prediction}$ = 0.7555, which indicates that this model should also be a reasonably good predictor. However, with a different sample, this could change.

#### Question 5

Based on the models you fitted from the previous 2 parts, compare the standard errors of the regression coefficients for both models.

The standard errors of the regression coefficients are higher in the model based on half of the data than in the model based on all 28 observations.

#### Question 6

Using  both  models,  calculate  the  predicted  number  of  wins  for  all  the  NFL  teams. Compare these models in terms of how well they predict the number of wins for all the NFL teams by computing the $SS_{res}$ for both models.

```{r}
mod1_preds <- predict.lm(nfl_lm, nfl)
mod2_preds <- predict.lm(nfl_lm_sample, nfl)

mod1_preds
```

```{r}
anova(nfl_lm)
anova(nfl_lm_sample)
```

The sum of squares of residuals is lower for the model based on the sample than for the original model.

```{r}
anova(lm(y ~ x2 + x7 + x8, data = nfl[sample(nrow(nfl), 14), ]))
```

